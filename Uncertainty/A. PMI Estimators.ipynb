{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de266823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 07:51:52.172700: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-01 07:51:52.172764: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-01 07:51:52.172788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-01 07:51:52.179889: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.datasets import load_dataset, preprocess_dataset, prefetch_dataset\n",
    "from src.pmi_estimators import train_critic_model, neural_pmi\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b541ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = { 'dataset' : 'mnist',\n",
    "        'model' : 'mlp',\n",
    "        'batch_size' : 512,\n",
    "        'optimizer' : 'Adam',\n",
    "        'learning_rate' : 0.001,\n",
    "        'max_epoch' : 300,\n",
    "        'patience' : 10,}    \n",
    "\n",
    "model_name = cfg['model']\n",
    "dataset_name = cfg['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d706aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 16:59:43.603447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1128 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n",
      "2024-01-30 16:59:44.937705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train error: 4.78, std: 1.11\n",
      "Average validation error: 19.40, std: 0.38\n",
      "Average test error: 20.17, std: 0.39\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#\n",
    "# Compute classification error\n",
    "#\n",
    "# #############################################################\n",
    "ds_train, ds_val, ds_test, ds_info = load_dataset(cfg)\n",
    "n_classes = ds_info.features['label'].num_classes\n",
    "ds_train = preprocess_dataset(ds_train, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "ds_val = preprocess_dataset(ds_val, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "ds_train = prefetch_dataset(ds_train, batch_size=cfg['batch_size'])\n",
    "ds_val = prefetch_dataset(ds_val, batch_size=cfg['batch_size'])\n",
    "ds_test = prefetch_dataset(ds_test, batch_size=cfg['batch_size'])\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "for run in range(5):\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "    train_acc.append(model.evaluate(ds_train, verbose=0)[1])\n",
    "    val_acc.append(model.evaluate(ds_val, verbose=0)[1])\n",
    "    test_acc.append(model.evaluate(ds_test, verbose=0)[1])\n",
    "print(f'Average train error: {(100-np.mean(train_acc)*100):.2f}, std: {(np.std(train_acc)*100):.2f}')\n",
    "print(f'Average validation error: {(100-np.mean(val_acc)*100):.2f}, std: {(np.std(val_acc)*100):.2f}')\n",
    "print(f'Average test error: {(100-np.mean(test_acc)*100):.2f}, std: {(np.std(test_acc)*100):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25bbb8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_probabilistic_classifier\n",
      "Training PMI model (concat, probabilistic_classifier)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 13:22:49.210875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f57f2346c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-30 13:22:49.210921: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-01-30 13:22:49.215881: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-30 13:22:49.337300: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_density_ratio_fitting\n",
      "Training PMI model (concat, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_variational_f_js\n",
      "Training PMI model (concat, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_probabilistic_classifier\n",
      "Training PMI model (separable, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model (separable, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_1/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 2\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_probabilistic_classifier\n",
      "Training PMI model (concat, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_density_ratio_fitting\n",
      "Training PMI model (concat, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_variational_f_js\n",
      "Training PMI model (concat, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_probabilistic_classifier\n",
      "Training PMI model (separable, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model (separable, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_2/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 3\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_probabilistic_classifier\n",
      "Training PMI model (concat, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_density_ratio_fitting\n",
      "Training PMI model (concat, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_variational_f_js\n",
      "Training PMI model (concat, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_probabilistic_classifier\n",
      "Training PMI model (separable, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model (separable, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_3/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 4\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_probabilistic_classifier\n",
      "Training PMI model (concat, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_density_ratio_fitting\n",
      "Training PMI model (concat, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_variational_f_js\n",
      "Training PMI model (concat, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_probabilistic_classifier\n",
      "Training PMI model (separable, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model (separable, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_4/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 5\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_probabilistic_classifier\n",
      "Training PMI model (concat, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_density_ratio_fitting\n",
      "Training PMI model (concat, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_variational_f_js\n",
      "Training PMI model (concat, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/concat_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_probabilistic_classifier\n",
      "Training PMI model (separable, probabilistic_classifier)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_probabilistic_classifier/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Making directory ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model (separable, variational_f_js)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/cnn_cifar10/run_5/calibration/pmi/separable_variational_f_js/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n"
     ]
    }
   ],
   "source": [
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "epochs = 100\n",
    "\n",
    "for run in range(5):\n",
    "    print(f'Run: {run+1}')\n",
    "    for critic in critic_list:\n",
    "        for estimator in estimators_list:\n",
    "            tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "            if not os.path.exists(exp_name):\n",
    "                print(\"Making directory\", exp_name)\n",
    "                os.makedirs(exp_name)\n",
    "                \n",
    "            ds_train, ds_val, ds_test, ds_info = load_dataset(cfg)\n",
    "            n_classes = ds_info.features['label'].num_classes\n",
    "            ds_train = preprocess_dataset(ds_train, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            ds_val = preprocess_dataset(ds_val, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            \n",
    "            model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "            int_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "            ##############################################################\n",
    "            #\n",
    "            # Train PMI Model\n",
    "            #\n",
    "            # #############################################################\n",
    "        \n",
    "            print(f'Training PMI model ({critic}, {estimator})...')\n",
    "            ds_activity = ds_train.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "            train_critic_model(ds_activity, critic=critic, estimator=estimator, epochs=epochs, save_path=f'{exp_name}/pmi_model')\n",
    "                                                                              \n",
    "            ##############################################################\n",
    "            #\n",
    "            # Compute PMI for all validation and test samples\n",
    "            #\n",
    "            # #############################################################\n",
    "\n",
    "            pmi_model = tf.keras.models.load_model(f'{exp_name}/pmi_model')\n",
    "            \n",
    "            print(f'Computing PMI for all validation samples and for all classes...')\n",
    "            pmi_class = []\n",
    "            for k in range(n_classes):\n",
    "                ds_activity = ds_val.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), tf.one_hot(tf.fill([tf.shape(x)[0]], k), depth=n_classes))).cache().prefetch(tf.data.AUTOTUNE)\n",
    "                pmi_list = []\n",
    "                for (x_batch, y_batch) in ds_activity:\n",
    "                    pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator=estimator)\n",
    "                    pmi_list += np.array(pmi).tolist()\n",
    "                pmi_class.append(pmi_list)\n",
    "            np.save(f'{exp_name}/pmi_class_val.npy', np.array(pmi_class).T)\n",
    "            \n",
    "            print(f'Computing PMI for all test samples and for all classes...')\n",
    "            pmi_class = []\n",
    "            for k in range(n_classes):\n",
    "                ds_activity = ds_test.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), tf.one_hot(tf.fill([tf.shape(x)[0]], k), depth=n_classes))).cache().prefetch(tf.data.AUTOTUNE)\n",
    "                pmi_list = []\n",
    "                for (x_batch, y_batch) in ds_activity:\n",
    "                    pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator=estimator)\n",
    "                    pmi_list += np.array(pmi).tolist()\n",
    "                pmi_class.append(pmi_list)\n",
    "            np.save(f'{exp_name}/pmi_class_test.npy', np.array(pmi_class).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f432d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: -3.779, Test filtering error:-79.05\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.452, Test filtering error:-81.69\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: -1.094, Test filtering error:-79.99\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 1.234, Test filtering error:-79.90\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 1.848, Test filtering error:-80.90\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: -2.010, Test filtering error:-79.81\n",
      "Run: 2\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: -7.448, Test filtering error:-78.93\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.194, Test filtering error:-82.36\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.140, Test filtering error:-81.36\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 1.521, Test filtering error:-81.05\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 1.975, Test filtering error:-81.52\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.006, Test filtering error:-80.27\n",
      "Run: 3\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: -3.502, Test filtering error:-79.06\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.415, Test filtering error:-81.95\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.767, Test filtering error:-81.30\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.831, Test filtering error:-80.21\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.393, Test filtering error:-81.55\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: -0.841, Test filtering error:-80.29\n",
      "Run: 4\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: -8.961, Test filtering error:-78.97\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.383, Test filtering error:-81.95\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.173, Test filtering error:-80.51\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.977, Test filtering error:-80.07\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.111, Test filtering error:-81.73\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.077, Test filtering error:-80.28\n",
      "Run: 5\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: -7.990, Test filtering error:-78.07\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 2.399, Test filtering error:-80.92\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.370, Test filtering error:-79.81\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 1.564, Test filtering error:-79.55\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 1.847, Test filtering error:-80.36\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: -0.405, Test filtering error:-79.37\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#\n",
    "# Compute Filtering Accuracy (without softmax scaling)\n",
    "#\n",
    "# #############################################################\n",
    "\n",
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for run in range(5):\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    print(f'Run: {run+1}')\n",
    "    for critic in critic_list:\n",
    "        for estimator in estimators_list:\n",
    "            print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "\n",
    "            ds_train, ds_val, ds_test, ds_info = load_dataset(cfg)\n",
    "            n_classes = ds_info.features['label'].num_classes\n",
    "            ds_val = preprocess_dataset(ds_val, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "            \n",
    "            true_y = np.argmax([y for x,y in ds_val], axis=1)\n",
    "            pred_y = np.argmax(model.predict(ds_val.batch(cfg['batch_size']), verbose=0), axis=1)\n",
    "            true_label = np.equal(true_y, pred_y).astype(int) # assign 0 if true_y != pred_y, assign 1 if true_y == pred_y\n",
    "            pmi_class = np.load(f'{exp_name}/pmi_class_val.npy')\n",
    "            pmi = [pmi_value[pred_value] for pmi_value, pred_value in zip(pmi_class, pred_y)]\n",
    "            opt_threshold = compute_opt_threshold(pmi, true_label)\n",
    "        \n",
    "            true_y = np.argmax([y for x,y in ds_test], axis=1)\n",
    "            pred_y = np.argmax(model.predict(ds_test.batch(cfg['batch_size']), verbose=0), axis=1)\n",
    "            true_label = np.equal(true_y, pred_y).astype(int) # assign 0 if true_y != pred_y, assign 1 if true_y == pred_y\n",
    "            pmi_class = np.load(f'{exp_name}/pmi_class_test.npy')\n",
    "            pmi = [pmi_value[pred_value] for pmi_value, pred_value in zip(pmi_class, pred_y)]\n",
    "            test_filtering_acc = compute_filtering_acc(pmi, true_label, opt_threshold)\n",
    "            \n",
    "            np.savez(f'{exp_name}/unscaled_filtering_accuracy.npz', opt_threshold=opt_threshold, test_filtering_acc=test_filtering_acc)\n",
    "            print(f'Opt. threshold: {opt_threshold:.3f}, Test filtering error:{100-test_filtering_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6df4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Average opt. threshold: -6.336, std: 2.255\n",
      "Average test filtering error: 20.18, std: 0.38\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Average opt. threshold: 2.369, std: 0.090\n",
      "Average test filtering error: 17.23, std: 0.48\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Average opt. threshold: 0.071, std: 0.624\n",
      "Average test filtering error: 18.41, std: 0.64\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Average opt. threshold: 1.226, std: 0.290\n",
      "Average test filtering error: 18.84, std: 0.50\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Average opt. threshold: 2.035, std: 0.204\n",
      "Average test filtering error: 17.79, std: 0.51\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Average opt. threshold: -0.634, std: 0.762\n",
      "Average test filtering error: 19.00, std: 0.37\n"
     ]
    }
   ],
   "source": [
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for critic in critic_list:\n",
    "    for estimator in estimators_list:\n",
    "        threshold = []\n",
    "        filtering_acc = []\n",
    "        for run in range(5):\n",
    "            tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "            f = np.load(f'{exp_name}/unscaled_filtering_accuracy.npz')\n",
    "            opt_threshold = f['opt_threshold']\n",
    "            test_filtering_acc = f['test_filtering_acc']\n",
    "            threshold.append(opt_threshold)\n",
    "            filtering_acc.append(test_filtering_acc)\n",
    "            \n",
    "        print('-----------------------------')\n",
    "        print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "        print(f'Average opt. threshold: {(np.mean(threshold)):.3f}, std: {(np.std(threshold)):.3f}')\n",
    "        print(f'Average test filtering error: {(100-np.mean(filtering_acc)):.2f}, std: {(np.std(filtering_acc)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f26591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Critic: concat, Estimator: probabilistic_classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 07:53:26.740701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78835 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt. threshold: 0.531, Test filtering error:1.71\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.407, Test filtering error:1.64\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.646, Test filtering error:1.65\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.419, Test filtering error:1.63\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.399, Test filtering error:1.71\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.032, Test filtering error:1.73\n",
      "Run: 2\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.000, Test filtering error:1.90\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.173, Test filtering error:1.84\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.147, Test filtering error:1.79\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.141, Test filtering error:1.73\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.422, Test filtering error:1.77\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.053, Test filtering error:1.73\n",
      "Run: 3\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.187, Test filtering error:1.79\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.521, Test filtering error:1.62\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.496, Test filtering error:1.67\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.674, Test filtering error:1.66\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.414, Test filtering error:1.71\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.106, Test filtering error:1.64\n",
      "Run: 4\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.641, Test filtering error:1.67\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.505, Test filtering error:1.68\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.525, Test filtering error:1.65\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.711, Test filtering error:1.73\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.595, Test filtering error:1.70\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.541, Test filtering error:1.68\n",
      "Run: 5\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.612, Test filtering error:1.81\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.417, Test filtering error:1.63\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Opt. threshold: 0.445, Test filtering error:1.70\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Opt. threshold: 0.450, Test filtering error:1.72\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Opt. threshold: 0.389, Test filtering error:1.80\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Opt. threshold: 0.391, Test filtering error:1.74\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#\n",
    "# Compute Filtering Accuracy (with softmax scaling)\n",
    "#\n",
    "# #############################################################\n",
    "\n",
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for run in range(5):\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    print(f'Run: {run+1}')\n",
    "    for critic in critic_list:\n",
    "        for estimator in estimators_list:\n",
    "            print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "\n",
    "            ds_train, ds_val, ds_test, ds_info = load_dataset(cfg, shuffle=False)\n",
    "            n_classes = ds_info.features['label'].num_classes\n",
    "            ds_val = preprocess_dataset(ds_val, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "            \n",
    "            true_y = np.argmax([y for x,y in ds_val], axis=1)\n",
    "            pred_y = np.argmax(model.predict(ds_val.batch(cfg['batch_size']), verbose=0), axis=1)\n",
    "            true_label = np.equal(true_y, pred_y).astype(int) # assign 0 if true_y != pred_y, assign 1 if true_y == pred_y\n",
    "            pmi_class = np.load(f'{exp_name}/pmi_class_val.npy')\n",
    "            pmi_class = np.array([softmax(x) for x in pmi_class])\n",
    "            pmi = [pmi_value[pred_value] for pmi_value, pred_value in zip(pmi_class, pred_y)]\n",
    "            opt_threshold = compute_opt_threshold(pmi, true_label)\n",
    "        \n",
    "            true_y = np.argmax([y for x,y in ds_test], axis=1)\n",
    "            pred_y = np.argmax(model.predict(ds_test.batch(cfg['batch_size']), verbose=0), axis=1)\n",
    "            true_label = np.equal(true_y, pred_y).astype(int) # assign 0 if true_y != pred_y, assign 1 if true_y == pred_y\n",
    "            pmi_class = np.load(f'{exp_name}/pmi_class_test.npy')\n",
    "            pmi_class = np.array([softmax(x) for x in pmi_class])\n",
    "            pmi = [pmi_value[pred_value] for pmi_value, pred_value in zip(pmi_class, pred_y)]\n",
    "            test_filtering_acc = compute_filtering_acc(pmi, true_label, opt_threshold)\n",
    "            \n",
    "            np.savez(f'{exp_name}/scaled_filtering_accuracy.npz', opt_threshold=opt_threshold, test_filtering_acc=test_filtering_acc)\n",
    "            print(f'Opt. threshold: {opt_threshold:.3f}, Test filtering error:{100-test_filtering_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b79029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Average opt. threshold: 0.394, std: 0.255\n",
      "Average test filtering error: 1.78, std: 0.08\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Average opt. threshold: 0.405, std: 0.125\n",
      "Average test filtering error: 1.68, std: 0.08\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Average opt. threshold: 0.452, std: 0.166\n",
      "Average test filtering error: 1.69, std: 0.05\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Average opt. threshold: 0.479, std: 0.205\n",
      "Average test filtering error: 1.69, std: 0.04\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Average opt. threshold: 0.444, std: 0.076\n",
      "Average test filtering error: 1.74, std: 0.04\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Average opt. threshold: 0.225, std: 0.204\n",
      "Average test filtering error: 1.70, std: 0.04\n"
     ]
    }
   ],
   "source": [
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for critic in critic_list:\n",
    "    for estimator in estimators_list:\n",
    "        threshold = []\n",
    "        filtering_acc = []\n",
    "        for run in range(5):\n",
    "            tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "            f = np.load(f'{exp_name}/scaled_filtering_accuracy.npz')\n",
    "            opt_threshold = f['opt_threshold']\n",
    "            test_filtering_acc = f['test_filtering_acc']\n",
    "            threshold.append(opt_threshold)\n",
    "            filtering_acc.append(test_filtering_acc)\n",
    "            \n",
    "        print('-----------------------------')\n",
    "        print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "        print(f'Average opt. threshold: {(np.mean(threshold)):.3f}, std: {(np.std(threshold)):.3f}')\n",
    "        print(f'Average test filtering error: {(100-np.mean(filtering_acc)):.2f}, std: {(np.std(filtering_acc)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a32c1208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "ECE: 1.08\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "ECE: 2.01\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "ECE: 1.26\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "ECE: 1.17\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "ECE: 0.93\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "ECE: 1.41\n",
      "Run: 2\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "ECE: 0.99\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "ECE: 2.53\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "ECE: 1.29\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "ECE: 1.13\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "ECE: 0.75\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "ECE: 1.37\n",
      "Run: 3\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "ECE: 1.05\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "ECE: 4.05\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "ECE: 1.34\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "ECE: 1.09\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "ECE: 0.74\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "ECE: 1.37\n",
      "Run: 4\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "ECE: 1.02\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "ECE: 3.44\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "ECE: 1.35\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "ECE: 1.15\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "ECE: 0.85\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "ECE: 1.46\n",
      "Run: 5\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "ECE: 1.23\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "ECE: 2.09\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "ECE: 1.39\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "ECE: 1.29\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "ECE: 0.90\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "ECE: 1.51\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#\n",
    "# Compute ECE (with softmax scaling)\n",
    "#\n",
    "# #############################################################\n",
    "\n",
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for run in range(5):\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    print(f'Run: {run+1}')\n",
    "    for critic in critic_list:\n",
    "        for estimator in estimators_list:\n",
    "            print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "\n",
    "            ds_train, ds_val, ds_test, ds_info = load_dataset(cfg)\n",
    "            n_classes = ds_info.features['label'].num_classes\n",
    "            ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=False, normalize=True, onehot=True)\n",
    "            model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "            \n",
    "            true_y = np.argmax([y for x,y in ds_test], axis=1)\n",
    "            pred_y = np.argmax(model.predict(ds_test.batch(cfg['batch_size']), verbose=0), axis=1)\n",
    "            pmi_class = np.load(f'{exp_name}/pmi_class_test.npy')\n",
    "            pmi_class = np.array([softmax(x) for x in pmi_class])\n",
    "            pmi = np.array([pmi_value[pred_value] for pmi_value, pred_value in zip(pmi_class, pred_y)])\n",
    "            ece = compute_ece(pmi, true_y, pred_y, n_bins=10)\n",
    "            \n",
    "            np.save(f'{exp_name}/ece_test.npy', ece)\n",
    "            print(f'ECE: {ece:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f53dcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Critic: concat, Estimator: probabilistic_classifier\n",
      "Average ECE: 1.08, std: 0.08\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: density_ratio_fitting\n",
      "Average ECE: 2.82, std: 0.80\n",
      "-----------------------------\n",
      "Critic: concat, Estimator: variational_f_js\n",
      "Average ECE: 1.33, std: 0.05\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: probabilistic_classifier\n",
      "Average ECE: 1.17, std: 0.07\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: density_ratio_fitting\n",
      "Average ECE: 0.83, std: 0.08\n",
      "-----------------------------\n",
      "Critic: separable, Estimator: variational_f_js\n",
      "Average ECE: 1.42, std: 0.05\n"
     ]
    }
   ],
   "source": [
    "critic_list = ['concat', 'separable']\n",
    "estimators_list = ['probabilistic_classifier', 'density_ratio_fitting', 'variational_f_js']\n",
    "\n",
    "for critic in critic_list:\n",
    "    for estimator in estimators_list:\n",
    "        ece_list = []\n",
    "        for run in range(5):\n",
    "            tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "            exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "            ece = np.load(f'{exp_name}/ece_test.npy')\n",
    "            ece_list.append(ece)\n",
    "            \n",
    "        print('-----------------------------')\n",
    "        print(f'Critic: {critic}, Estimator: {estimator}')\n",
    "        print(f'Average ECE: {(np.mean(ece_list)):.2f}, std: {(np.std(ece_list)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c68eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = { 'dataset' : 'stl10',\n",
    "        'model' : 'pretrained_inception',\n",
    "        'batch_size' : 512,\n",
    "        'optimizer' : 'Adam',\n",
    "        'learning_rate' : 0.001,\n",
    "        'max_epoch' : 300,\n",
    "        'patience' : 10,}    \n",
    "\n",
    "model_name = cfg['model']\n",
    "dataset_name = cfg['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9b011c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_1/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_1/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 2\n",
      "Making directory ../results/PI_Explainability/pretrained_inception_stl10/run_2/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_2/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_2/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 3\n",
      "Making directory ../results/PI_Explainability/pretrained_inception_stl10/run_3/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_3/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_3/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 4\n",
      "Making directory ../results/PI_Explainability/pretrained_inception_stl10/run_4/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_4/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_4/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n",
      "Run: 5\n",
      "Making directory ../results/PI_Explainability/pretrained_inception_stl10/run_5/calibration/pmi/separable_density_ratio_fitting\n",
      "Training PMI model (separable, density_ratio_fitting)...\n",
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_5/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/pretrained_inception_stl10/run_5/calibration/pmi/separable_density_ratio_fitting/pmi_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n",
      "Computing PMI for all test samples and for all classes...\n"
     ]
    }
   ],
   "source": [
    "critic = 'separable'\n",
    "estimator = 'density_ratio_fitting'\n",
    "epochs = 100\n",
    "\n",
    "for run in range(5):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/{critic}_{estimator}'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "\n",
    "    ds_train, ds_val, ds_test, ds_info = load_dataset(cfg)\n",
    "    n_classes = ds_info.features['label'].num_classes\n",
    "    ds_train = preprocess_dataset(ds_train, cfg, n_classes, resize=True, normalize=True, onehot=True)\n",
    "    ds_val = preprocess_dataset(ds_val, cfg, n_classes, resize=True, normalize=True, onehot=True)\n",
    "    ds_test = preprocess_dataset(ds_test, cfg, n_classes, resize=True, normalize=True, onehot=True)\n",
    "\n",
    "    model = tf.keras.models.load_model(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/trained_model.keras')\n",
    "    int_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PMI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    print(f'Training PMI model ({critic}, {estimator})...')\n",
    "    ds_activity = ds_train.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    train_critic_model(ds_activity, critic=critic, estimator=estimator, epochs=epochs, save_path=f'{exp_name}/pmi_model')\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PMI for all validation and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    pmi_model = tf.keras.models.load_model(f'{exp_name}/pmi_model')\n",
    "\n",
    "    print(f'Computing PMI for all validation samples and for all classes...')\n",
    "    pmi_class = []\n",
    "    for k in range(n_classes):\n",
    "        ds_activity = ds_val.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), tf.one_hot(tf.fill([tf.shape(x)[0]], k), depth=n_classes))).cache().prefetch(tf.data.AUTOTUNE)\n",
    "        pmi_list = []\n",
    "        for (x_batch, y_batch) in ds_activity:\n",
    "            pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator=estimator)\n",
    "            pmi_list += np.array(pmi).tolist()\n",
    "        pmi_class.append(pmi_list)\n",
    "    np.save(f'{exp_name}/pmi_class_val.npy', np.array(pmi_class).T)\n",
    "\n",
    "    print(f'Computing PMI for all test samples and for all classes...')\n",
    "    pmi_class = []\n",
    "    for k in range(n_classes):\n",
    "        ds_activity = ds_test.batch(cfg['batch_size']).map(lambda x, y: (int_model(x), tf.one_hot(tf.fill([tf.shape(x)[0]], k), depth=n_classes))).cache().prefetch(tf.data.AUTOTUNE)\n",
    "        pmi_list = []\n",
    "        for (x_batch, y_batch) in ds_activity:\n",
    "            pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator=estimator)\n",
    "            pmi_list += np.array(pmi).tolist()\n",
    "        pmi_class.append(pmi_list)\n",
    "    np.save(f'{exp_name}/pmi_class_test.npy', np.array(pmi_class).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a01dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
